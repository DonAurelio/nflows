{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7eb6fe2a-1b94-4165-a403-f34bf8e16ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      data_item task_name cpu_node mem_node access_type\n",
      "0  Task1->Task2     Task2        0        0        read\n",
      "1  Task1->Task2     Task2        0        1        read\n",
      "2  Task1->Task3     Task3        0        0        read\n",
      "3  Task1->Task3     Task3        0        1        read\n",
      "4  Task1->Task3     Task1        0        0       write\n",
      "5  Task1->Task3     Task1        0        1       write\n",
      "6  Task1->Task2     Task1        0        0       write\n",
      "7  Task1->Task2     Task1        0        1       write\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "document = \"\"\"\n",
    "comm_name_to_numa_id:\n",
    "  Task1->Task3: NUMA IDs = 0 1 \n",
    "  Task1->Task2: NUMA IDs = 0 1 \n",
    "\n",
    "exec_name_to_locality:\n",
    "  Task2: NUMA ID = 0, Core ID = 2, Voluntary CS = 0, Involuntary CS = 83, Core Migrations = 0\n",
    "  Task3: NUMA ID = 0, Core ID = 20, Voluntary CS = 1, Involuntary CS = 27, Core Migrations = 0\n",
    "  Task1: NUMA ID = 0, Core ID = 23, Voluntary CS = 0, Involuntary CS = 33, Core Migrations = 0\n",
    "\"\"\"\n",
    "\n",
    "# print(yaml.dump(yaml.load(document, Loader=yaml.FullLoader), default_flow_style=False, allow_unicode=True, indent=4))\n",
    "\n",
    "data = yaml.load(document, Loader=yaml.FullLoader)\n",
    "\n",
    "# Extract relevant data\n",
    "exec_name_to_locality = data[\"exec_name_to_locality\"]\n",
    "comm_name_to_numa_id = data[\"comm_name_to_numa_id\"]\n",
    "\n",
    "# Initialize an empty list to store rows for the DataFrame\n",
    "rows = []\n",
    "\n",
    "# Process each task_name and cpu_node from exec_name_to_locality\n",
    "for task_name, locality in exec_name_to_locality.items():\n",
    "    cpu_node = locality.split(\"NUMA ID = \")[1].split(\",\")[0].strip()\n",
    "    \n",
    "    # Check if task_name exists in comm_name_to_numa_id\n",
    "    for comm_name, numa_ids in comm_name_to_numa_id.items():\n",
    "        if task_name in comm_name:\n",
    "            mem_nodes = numa_ids.split(\"NUMA IDs = \")[1].strip().split()\n",
    "            # Determine the access type (write if task_name is on the left, read if on the right)\n",
    "            access_type = \"write\" if comm_name.split(\"->\")[0] == task_name else \"read\"\n",
    "            # Add rows for each mem_node with access type and comm_name as data_item\n",
    "            for mem_node in mem_nodes:\n",
    "                rows.append([comm_name, task_name, cpu_node, mem_node, access_type])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(rows, columns=[\"data_item\", \"task_name\", \"cpu_node\", \"mem_node\", \"access_type\"])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80fb6ac9-1d1b-481d-a179-fff55ce39ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Data (cpu_node == mem_node):\n",
      "  cpu_node mem_node  count\n",
      "0        0        0      4\n",
      "\n",
      "Aggregated Data (cpu_node != mem_node):\n",
      "  cpu_node mem_node  count\n",
      "0        0        1      4\n"
     ]
    }
   ],
   "source": [
    "# Function to aggregate based on equal or different cpu_node and mem_node\n",
    "def aggregate_data(df, equal=True):\n",
    "    if equal:\n",
    "        # Aggregate when cpu_node and mem_node are equal\n",
    "        aggregated_df = df[df['cpu_node'] == df['mem_node']].groupby(['cpu_node', 'mem_node']).size().reset_index(name='count')\n",
    "    else:\n",
    "        # Aggregate when cpu_node and mem_node are different\n",
    "        aggregated_df = df[df['cpu_node'] != df['mem_node']].groupby(['cpu_node', 'mem_node']).size().reset_index(name='count')\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "# Example usage: aggregate when cpu_node and mem_node are equal\n",
    "equal_aggregated_df = aggregate_data(df, equal=True)\n",
    "print(\"Aggregated Data (cpu_node == mem_node):\")\n",
    "print(equal_aggregated_df)\n",
    "\n",
    "# Example usage: aggregate when cpu_node and mem_node are different\n",
    "different_aggregated_df = aggregate_data(df, equal=False)\n",
    "print(\"\\nAggregated Data (cpu_node != mem_node):\")\n",
    "print(different_aggregated_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
